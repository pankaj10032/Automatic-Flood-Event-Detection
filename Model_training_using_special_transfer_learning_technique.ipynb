{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The preprocessing stage was completed on my personal system. As training requires a GPU, I proceeded to train the model on Google Colab and imported all the preprocessed data from Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RE_UvyEcAl8z",
        "outputId": "50fbd976-5086-45f5-eeea-de13cc78a29d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hq1rciHWAuyz"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXmF5d2hAxJR"
      },
      "outputs": [],
      "source": [
        "train_images = np.load('/content/drive/MyDrive/Dataset/sen12_compressed/train_images.npy')\n",
        "train_labels = np.load('/content/drive/MyDrive/Dataset/sen12_compressed/train_labels.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHyBSSbJAx42"
      },
      "outputs": [],
      "source": [
        "test_images = np.load('/content/drive/MyDrive/Dataset/sen12_compressed/test_images.npy')\n",
        "test_labels = np.load('/content/drive/MyDrive/Dataset/sen12_compressed/test_labels.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BViHVt8vOtJ_"
      },
      "outputs": [],
      "source": [
        "#rescaling of train_image(All the images are 16 bit image so max value of each pixel can be 2^16-1 = 65535)\n",
        "train_images = train_images.astype(np.float32)\n",
        "train_labels = train_labels.astype(np.int32)\n",
        "\n",
        "train_images /= 65535.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eXGfVuKJOuhl"
      },
      "outputs": [],
      "source": [
        "test_images = test_images.astype(np.float32)\n",
        "test_labels = test_labels.astype(np.int32)\n",
        "\n",
        "test_images /= 65535.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGIpuyMLA713",
        "outputId": "944ef490-3fec-4236-abcc-ba83df63176d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1750, 256, 256, 4)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smIzMAZkA9eV",
        "outputId": "8d356ef8-fc02-49df-da87-7ae05f24f011"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1750,)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_labels.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVaq8tZwCtp2"
      },
      "outputs": [],
      "source": [
        "fourth_channel_train_images = train_images[:, :, :, 3:]\n",
        "train_images = train_images[:, :, :, :3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQxhY2SI83nZ"
      },
      "outputs": [],
      "source": [
        "modified_images = np.repeat(fourth_channel_train_images, repeats=3, axis=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IF2W254z9slw",
        "outputId": "1972b858-b6f2-4130-a328-3a0aec29a5ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1750, 256, 256, 3)\n",
            "(1750, 256, 256, 3)\n"
          ]
        }
      ],
      "source": [
        "print(modified_images.shape)\n",
        "print(train_images.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eE8qdj7bBAaQ",
        "outputId": "5467677a-984c-4b49-fcc4-c0ee6ed6211e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of images in the train dataset containing flooded areas is 394\n",
            "\n",
            "While the number of images clean from floods is 1356\n"
          ]
        }
      ],
      "source": [
        "(unique, counts) = np.unique(train_labels, return_counts=True)\n",
        "\n",
        "print(f\"The number of images in the train dataset containing flooded areas is {counts[1]}\\n\")\n",
        "print(f\"While the number of images clean from floods is {counts[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbprZldJBJ9Z"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, concatenate\n",
        "from tensorflow.keras.applications import ResNet152\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLmHmt0oAMCu"
      },
      "outputs": [],
      "source": [
        "# resize_and_rescale = tf.keras.Sequential([\n",
        "#     # tf.print(\"hello\")\n",
        "#     tf.keras.layers.Lambda(lambda x: tf.print(x)),\n",
        "#     #tf.keras.layers.Lambda(lambda x: tf.cast(x, tf.float32)),\n",
        "#     #tf.keras.layers.experimental.preprocessing.Rescaling(1./65535.0),\n",
        "# ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_COj2VUiBFPE"
      },
      "outputs": [],
      "source": [
        "# Define the input shape\n",
        "input_shape = (256, 256, 3)\n",
        "\n",
        "# Load the pre-trained ResNet-152 model without the top (classification) layers\n",
        "base_model = ResNet152(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "# Freeze the pre-trained layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Create the input tensors for two images\n",
        "input_tensor_1 = tf.keras.Input(shape=input_shape)\n",
        "input_tensor_2 = tf.keras.Input(shape=input_shape)\n",
        "\n",
        "# Apply the pre-trained ResNet-152 model to the first input tensor\n",
        "x1 = base_model(input_tensor_1, training=True)\n",
        "\n",
        "# Apply the pre-trained ResNet-152 model to the second input tensor\n",
        "x2 = base_model(input_tensor_2, training=True)\n",
        "\n",
        "# Concatenate the outputs of the two base models\n",
        "concatenated = concatenate([x1, x2])\n",
        "\n",
        "# Add your own classification layers on top of the concatenated features\n",
        "x = GlobalAveragePooling2D()(concatenated)\n",
        "x = Dense(8000, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)  # Add a dropout layer with a dropout rate of 0.5\n",
        "x = Dense(4000, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)  # Add another dropout layer with a dropout rate of 0.5\n",
        "x = Dense(2000, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)  # Add another dropout layer with a dropout rate of 0.5\n",
        "x = Dense(1000, activation='relu')(x)\n",
        "predictions = Dense(2, activation='softmax')(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_m9-b5G-Dgc"
      },
      "outputs": [],
      "source": [
        "# Create the final model\n",
        "with tf.device('/GPU:0'):\n",
        "  model = Model(inputs=[input_tensor_1, input_tensor_2], outputs=predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1I1mkdyTAGQv"
      },
      "outputs": [],
      "source": [
        "# with tf.device('/GPU:0'):\n",
        "#   model = tf.keras.Sequential([resize_and_rescale, model])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1sEdTIe-4YH"
      },
      "outputs": [],
      "source": [
        "with tf.device('/GPU:0'):\n",
        "  model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T236SRnABkhP"
      },
      "outputs": [],
      "source": [
        "# Train the model with your dataset\n",
        "with tf.device('/GPU:0'):\n",
        "  history = model.fit([train_images, modified_images], train_labels, batch_size=12, epochs=55, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ausYSh1kZdsb"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_cXf3WCHeUS"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/MyDrive/Flood_Dtection_Model/resnet_tl_grey.h')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
